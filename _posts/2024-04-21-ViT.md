---
title: ViT
date: 2024-04-21 12:00:00 +/-TTTT
categories: [AI,CV]
tags: [AI,paper-learing,CV ]  # TAG names should always be lowercase
---

## ViT
**实验部分未结束**

### Abstract
将transformer应用到CV
### Itroduction
* CV with transformer Related Work
  * CNN + attention
  * attention取代CNN ---轴注意力  孤立注意力 ：难以加速
*  This work
   *  分割为patch 当作一个word
   *  在没有强的约束下，在训练量不够时，弱于CNN。原因是缺少在CNN中的归纳偏置（先验信息，例如相邻的图片有相近的数据）
### model
* patch enbeding + position enbeding
  * patch enbeding
    * 在token开头加上类cls的标记 最后通过该标记（在注意力机制中 该标记会与其他patch都就交互）来得到结果
    * 全连接层进行 patch enbeding  --》1d token
  * Position enbeding
    * 长度与patch enbeding 相同
    * 存在一个位置相关的表，取出相关位置得到向量，加上enbeding的结果，得到最后的结果
* Transformer encoder 
  * 与标准transformer相同 
  
* Classify
  * 基于cls token来分类

* CNN+transformer
  * 先用CNN输出特征图
  * 最后把特征图输入全连接层




### exprience
* contract
  * Classify
    * 基于cls token来分类（BERT的做法）
    * 基于平均池化 GAP 之后 再分类（CV的传统做法）
  * Position enbeding
    * 1'd encoding 本文采用的 NLP通用 输出D长度的位置enbeding
    * 2'd encoding 在纵坐标进行D/2的编码 在横坐标进行D/2的编码 拼接得到D长度
    * Relative position encoding

* self-supervision
  * masked patch prediction