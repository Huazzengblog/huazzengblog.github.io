---
title: intern
date: 2025-03-06 15:00:00 +/-TTTT
categories: [intern]
tags: [intern]  # TAG names should always be lowercase
---
# intern
## ML
### 算法
#### word 2 vec 
* Skip-grim和Cbow的区别？Skip-grim优势在哪？

  * A: 使用中心词预测上下文与使用上下文预测中心词的区别。使用Sg的训练更为细致，从BP的角度看待，Sg的输出节点为Cbow的K倍，则在反向传播时的计算次数时Cbow的K倍（Cbow原理上对上下文向量做了Average）。对于数据量较少或生僻词较多的时候，Sg能展现出明显优势。简单而言，Cbow训练速度更快，但Skip-grim更为准确，实际上论文中也指出了Sg效果更好。
* 加速方式
  * 高频词抽样
  * 负样本抽样
  * 哈夫曼树
#### GBDT
* XGBoost
* LightGBM
* CatBoost



#### 集成学习
* Bagging的基模型是强模型，常用投票法基于所有基模型预测结果输出最终结果，比较常见是的对每个基模型预测赋予相同的权重。Bagging能有效降低模型方差。

* Boosting训练过程为阶梯状，基模型训练时有序的，每个基模型都会基于前一个基模型进行训练，使用的是弱模型。

* Stacking将基模型的输出结果作为新的特征进行预测。使用的是强模型。
#### LR 
#### attention
${Attention}(Q, K, V) = \text{softmax} \left( \frac{QK^T}{\sqrt{d_k}} \right) V$
* transformer为什么要引入位置编码？

  * transformer处理的是时间序列，但与rnn不同的是transformer并不包含位置信息（encoder甚至可以并行计算），所以需要引入位置编码。
* Q，K，V表示什么含义？

  * Q就是token的查询向量，K是“被查”向量，V是内容向量。查询向量  与“被查”向量的kj的内积相似度作为vj的注意力得分（权重），token i attends to token j；

* 为什么attention计算要scaled？
  * 当 dkd_kd_k 的值变大的时候，softmax 函数会造成梯度消失问题，所以设置了一个 softmax 的 temperature 来缓解这个问题。这里 temperature 被设置为了     $\sqrt{d_k}$, 也就是乘上 $\frac{1}{\sqrt{d_k}}$.
* self attention


### 评价指标
#### cross entropy
  * softmax 反向求导
#### auc
* ROC曲线下的面积
  * TPR是把正样本正确预测成正样本的概率，FPR是把负样本错误的预测成正样本的概率
  * roc曲线的横坐标为FPR，纵坐标为TPR
  * 而曲线越靠近左上角，说明正样本中混入的负样本越少，模型对正负样本的区分能力越强，此时ROC曲线下方的面积越大；当给定某一个阈值时，正负样本刚好被隔开，即预测值大于该阈值的刚好都是正样本，预测值小于该阈值的刚好都是负样本，这个模型就可以认为是一个完美的模型，此时ROC曲线下方的面积就是1。
#### recall precision f1
* recall = TP / (TP + FN)
* precision = TP / (TP + FP)
* f1 = 2 * precision * recall / (precision + recall)


### 训练技巧
#### lora qlora



### optimazer
  * bgd
  * sgd
  * adam
  * adamw


## AI Agent
### MCP (model context protocol)
* 包含
  * tool
  * resource
  * prompt


### RAG


* 问题1:面试官：看到你之前参与过RAG得项目，能否分享一下RAG的合作流程？
  * 候选人：当然可以。RAG首先涉及文本分块。将文本分割成若干块，使用特定的模型将这些块嵌入到向量空间中。接下来，建立索引，创建提示来告诉模型，根据检索找到的上下文回答用户的查询。在运行时，会使用相同的向量来对用户的查询进行处理，然后执行向量搜索，在向量数据库中检索到最匹配的结果，并将这些结果作为上下文输入到大模型的提示词中，以生成总结性的答案。
* 问题2：面试官：您提到的是RAG的标准流程，那么在实际项目中，你还采用了哪些优化技巧？
  * 候选人：在实际应用中，我们会考虑多路召回策略，包括稀疏召回、语义召回和字面召回等。处理召回过程中的截断和召回分数对齐问题，通过在召回后加入重排序来精简召回数量、提升召回质量。此外，还会根据系统问答的指标，对嵌入模型、重排序模型和生成模型进行进一步的优化。
* 问题3面试官：明白了。你刚才提到了评价指标，那么您能描述一下RAG是如何进行效果评分的吗？
  * 候选人：RAG的效果评估主要针对检索和生成环节。我们可以使用平均倒排率，排序指标来进行评估。
* 问题4面试官：那么在生成环节，你是如何进行评估的呢？
  * 候选人：在生成环节，首先会使用量化指标，如ROUGE-L分数和文本相似度、关键词重合度等。其次评估生成答案的多样性，查看模型是否能够生成多种合理的答案。此外，引入人工评估，进行反向测试，主要评估模型的复杂性和质量。
* 问题5:面试官：好的，你觉得RAG在处理问题时有哪些挑战？候选人：RAG面临的挑战主要有两个：一是生成结果与数据源不一致，二是问题超出了模型的认知范围。对于第一种，可能是训练数据与源数据不一致，或者是编码理解能力不足。对于第二种情况，可能是用户的问题超出了模型的处理范围。问题6面试官：针对模型幻觉，你有哪些解决思路？
  * 候选人：解决这些问题，可以考虑引入更精确的数据源，消除虚假数据，并加入纠偏规则，比如采用re-act方法，让大模型对输出结果进行反思。另一种思路是集成知识库，不仅仅考虑向量匹配，还要考虑知识图谱中的三元组，将结构化的相关点数据集成到RAG系统中，以增强系统的推理能力。
* 问题7面试官：在实际项目中，您如何处理各种边界的case，意外的情况？
  * 候选人：这需要具体情况具体分析。对于无效问题，即知识库中没有答案的问题，需要进行准入判断，通常使用二分类模型加提示来处理。对于随时间变化的问题，我们可以在推理模块中添加规则和提示词，使模型在不确定时能够给出合适的回答。对于格式错误的问题，比如模型生成了无法解析的答案，我们可以使用备份的代理大模型，在解析失败时直接生成答案。