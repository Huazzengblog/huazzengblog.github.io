---
title: intern
date: 2025-03-06 15:00:00 +/-TTTT
categories: [intern]
tags: [intern]  # TAG names should always be lowercase
---
# intern
## ML
### 算法
#### word 2 vec 
* Skip-grim和Cbow的区别？Skip-grim优势在哪？

  * A: 使用中心词预测上下文与使用上下文预测中心词的区别。使用Sg的训练更为细致，从BP的角度看待，Sg的输出节点为Cbow的K倍，则在反向传播时的计算次数时Cbow的K倍（Cbow原理上对上下文向量做了Average）。对于数据量较少或生僻词较多的时候，Sg能展现出明显优势。简单而言，Cbow训练速度更快，但Skip-grim更为准确，实际上论文中也指出了Sg效果更好。
* 加速方式
  * 高频词抽样
  * 负样本抽样
  * 哈夫曼树
#### GBDT
* XGBoost
* LightGBM
* CatBoost

GBDT 是一种集成学习方法，它通过逐步构建一系列弱分类器（决策树）来优化模型。每一棵树的训练目的是拟合前一棵树的残差，最终将多棵树的结果加权平均得到最终预测。

##### **GBDT 树生长方式：**
- **Level-wise（深度优先）**：按层次逐层生长，每一层节点使用不同的特征分裂，适合并行计算。
- **Leaf-wise（叶子优先）**：优先选择增益最大叶子节点进行分裂，生成更加精细的树，精度较高，但容易过拟合。

##### **损失函数**：
GBDT 的损失函数通常是二次损失函数或类似的回归损失。对于每次迭代，通过最小化损失函数的梯度来训练树模型。

##### **XGBoost 和 CatBoost**：
- **XGBoost**：在 GBDT 基础上做了很多优化，包括并行计算、剪枝算法、正则化等，使得训练速度更快，模型更稳定。
- **CatBoost**：一个基于 GBDT 的算法，专门为处理类别特征设计，采用了 **Ordered Boosting** 和 **对称树结构**，提高了处理分类特征的能力，并有效避免了数据泄露问题。

##### **XGBoost 的并行运算：**
XGBoost 的并行计算是基于 **特征并行** 和 **数据并行** 两种方式：
- **特征并行**：每棵树的每个分裂点都在不同的线程上计算。
- **数据并行**：树的每个分裂过程在多个数据子集上并行计算。

##### **对称树结构（CatBoost）**：
CatBoost 使用对称树结构，在每一层中所有节点的分裂特征和分裂点是相同的，这使得树的结构更加平衡、稳定，并且减少了过拟合的风险。与传统的 **Level-wise** 和 **Leaf-wise** 方法不同，CatBoost 在每一层保证树的对称性，并且在梯度提升的框架下优化模型。

##### **CatBoost 的特点**：
1. **对称树结构**：每层的节点分裂特征一致，提升了训练稳定性，减少了过拟合。
2. **Ordered Boosting**：通过排序处理类别特征，避免了传统 GBDT 中的数据泄露问题。
3. **适用于类别特征**：CatBoost 通过独特的类别特征处理方法，在处理具有大量类别特征的数据集时表现出色。

##### **总结对比**：
- **Level-wise**（深度优先）树生长策略：每一层的节点使用不同的特征，适合平衡的任务和并行计算。
- **Leaf-wise**（叶子优先）树生长策略：优先选择增益最大叶子节点进行分裂，适合处理大数据量和复杂模式，但可能导致过拟合。
- **CatBoost** 对称树结构：每一层使用相同的特征和分裂点，确保树的结构平衡、稳定，避免了过拟合，并且通过 **Ordered Boosting** 有效处理类别特征。

##### **适用场景**：
- **XGBoost** 适合大规模数据，特别是在特征很多、样本多的任务中。
- **LightGBM** 在大数据、高维特征的环境下也非常有效，尤其在需要速度和精度的任务中。
- **CatBoost** 则在需要处理大量类别特征或防止数据泄露的任务中非常强大，特别是在需要高精度和避免过拟合的场景下。



#### 集成学习
* Bagging的基模型是强模型，常用投票法基于所有基模型预测结果输出最终结果，比较常见是的对每个基模型预测赋予相同的权重。Bagging能有效降低模型方差。

* Boosting训练过程为阶梯状，基模型训练时有序的，每个基模型都会基于前一个基模型进行训练，使用的是弱模型。

* Stacking将基模型的输出结果作为新的特征进行预测。使用的是强模型。
#### LR 
#### attention
${Attention}(Q, K, V) = \text{softmax} \left( \frac{QK^T}{\sqrt{d_k}} \right) V$
* transformer为什么要引入位置编码？

  * transformer处理的是时间序列，但与rnn不同的是transformer并不包含位置信息（encoder甚至可以并行计算），所以需要引入位置编码。
* Q，K，V表示什么含义？

  * Q就是token的查询向量，K是“被查”向量，V是内容向量。查询向量  与“被查”向量的kj的内积相似度作为vj的注意力得分（权重），token i attends to token j；

* 为什么attention计算要scaled？
  * 当 dkd_kd_k 的值变大的时候，softmax 函数会造成梯度消失问题，所以设置了一个 softmax 的 temperature 来缓解这个问题。这里 temperature 被设置为了     $\sqrt{d_k}$, 也就是乘上 $\frac{1}{\sqrt{d_k}}$.
* self attention


### 评价指标
#### cross entropy
  * softmax 反向求导
#### auc
* ROC曲线下的面积
  * TPR是把正样本正确预测成正样本的概率，FPR是把负样本错误的预测成正样本的概率
  * roc曲线的横坐标为FPR，纵坐标为TPR
  * 而曲线越靠近左上角，说明正样本中混入的负样本越少，模型对正负样本的区分能力越强，此时ROC曲线下方的面积越大；当给定某一个阈值时，正负样本刚好被隔开，即预测值大于该阈值的刚好都是正样本，预测值小于该阈值的刚好都是负样本，这个模型就可以认为是一个完美的模型，此时ROC曲线下方的面积就是1。
#### recall precision f1
* recall = TP / (TP + FN)
* precision = TP / (TP + FP)
* f1 = 2 * precision * recall / (precision + recall)


### 训练技巧
#### lora qlora



### optimazer
  * bgd
  * sgd
  * adam
  * adamw


## AI Agent
### MCP (model context protocol)
* 包含
  * tool
  * resource
  * prompt


### RAG


* 问题1:面试官：看到你之前参与过RAG得项目，能否分享一下RAG的合作流程？
  * 候选人：当然可以。RAG首先涉及文本分块。将文本分割成若干块，使用特定的模型将这些块嵌入到向量空间中。接下来，建立索引，创建提示来告诉模型，根据检索找到的上下文回答用户的查询。在运行时，会使用相同的向量来对用户的查询进行处理，然后执行向量搜索，在向量数据库中检索到最匹配的结果，并将这些结果作为上下文输入到大模型的提示词中，以生成总结性的答案。
* 问题2：面试官：您提到的是RAG的标准流程，那么在实际项目中，你还采用了哪些优化技巧？
  * 候选人：在实际应用中，我们会考虑多路召回策略，包括稀疏召回、语义召回和字面召回等。处理召回过程中的截断和召回分数对齐问题，通过在召回后加入重排序来精简召回数量、提升召回质量。此外，还会根据系统问答的指标，对嵌入模型、重排序模型和生成模型进行进一步的优化。
* 问题3面试官：明白了。你刚才提到了评价指标，那么您能描述一下RAG是如何进行效果评分的吗？
  * 候选人：RAG的效果评估主要针对检索和生成环节。我们可以使用平均倒排率，排序指标来进行评估。
* 问题4面试官：那么在生成环节，你是如何进行评估的呢？
  * 候选人：在生成环节，首先会使用量化指标，如ROUGE-L分数和文本相似度、关键词重合度等。其次评估生成答案的多样性，查看模型是否能够生成多种合理的答案。此外，引入人工评估，进行反向测试，主要评估模型的复杂性和质量。
* 问题5:面试官：好的，你觉得RAG在处理问题时有哪些挑战？候选人：RAG面临的挑战主要有两个：一是生成结果与数据源不一致，二是问题超出了模型的认知范围。对于第一种，可能是训练数据与源数据不一致，或者是编码理解能力不足。对于第二种情况，可能是用户的问题超出了模型的处理范围。问题6面试官：针对模型幻觉，你有哪些解决思路？
  * 候选人：解决这些问题，可以考虑引入更精确的数据源，消除虚假数据，并加入纠偏规则，比如采用re-act方法，让大模型对输出结果进行反思。另一种思路是集成知识库，不仅仅考虑向量匹配，还要考虑知识图谱中的三元组，将结构化的相关点数据集成到RAG系统中，以增强系统的推理能力。
* 问题7面试官：在实际项目中，您如何处理各种边界的case，意外的情况？
  * 候选人：这需要具体情况具体分析。对于无效问题，即知识库中没有答案的问题，需要进行准入判断，通常使用二分类模型加提示来处理。对于随时间变化的问题，我们可以在推理模块中添加规则和提示词，使模型在不确定时能够给出合适的回答。对于格式错误的问题，比如模型生成了无法解析的答案，我们可以使用备份的代理大模型，在解析失败时直接生成答案。