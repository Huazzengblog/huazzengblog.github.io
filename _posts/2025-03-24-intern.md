---
title: intern
date: 2025-03-06 15:00:00 +/-TTTT
categories: [intern]
tags: [intern]  # TAG names should always be lowercase
---
# intern
## ML
### 算法
#### word 2 vec 
* Skip-grim和Cbow的区别？Skip-grim优势在哪？

  * A: 使用中心词预测上下文与使用上下文预测中心词的区别。使用Sg的训练更为细致，从BP的角度看待，Sg的输出节点为Cbow的K倍，则在反向传播时的计算次数时Cbow的K倍（Cbow原理上对上下文向量做了Average）。对于数据量较少或生僻词较多的时候，Sg能展现出明显优势。简单而言，Cbow训练速度更快，但Skip-grim更为准确，实际上论文中也指出了Sg效果更好。
* 加速方式
  * 高频词抽样
  * 负样本抽样
  * 哈夫曼树
#### GBDT
* XGBoost
* LightGBM
* CatBoost



#### 集成学习
* Bagging的基模型是强模型，常用投票法基于所有基模型预测结果输出最终结果，比较常见是的对每个基模型预测赋予相同的权重。Bagging能有效降低模型方差。

* Boosting训练过程为阶梯状，基模型训练时有序的，每个基模型都会基于前一个基模型进行训练，使用的是弱模型。

* Stacking将基模型的输出结果作为新的特征进行预测。使用的是强模型。
#### LR 
#### attention
${Attention}(Q, K, V) = \text{softmax} \left( \frac{QK^T}{\sqrt{d_k}} \right) V$
* transformer为什么要引入位置编码？

  * transformer处理的是时间序列，但与rnn不同的是transformer并不包含位置信息（encoder甚至可以并行计算），所以需要引入位置编码。
* Q，K，V表示什么含义？

  * Q就是token的查询向量，K是“被查”向量，V是内容向量。查询向量  与“被查”向量的kj的内积相似度作为vj的注意力得分（权重），token i attends to token j；

* 为什么attention计算要scaled？
  * 当 dkd_kd_k 的值变大的时候，softmax 函数会造成梯度消失问题，所以设置了一个 softmax 的 temperature 来缓解这个问题。这里 temperature 被设置为了     $\sqrt{d_k}$, 也就是乘上 $\frac{1}{\sqrt{d_k}}$.
* self attention


### 评价指标
#### cross entropy
  * softmax 反向求导
#### auc
* ROC曲线下的面积
  * TPR是把正样本正确预测成正样本的概率，FPR是把负样本错误的预测成正样本的概率
  * roc曲线的横坐标为FPR，纵坐标为TPR
  * 而曲线越靠近左上角，说明正样本中混入的负样本越少，模型对正负样本的区分能力越强，此时ROC曲线下方的面积越大；当给定某一个阈值时，正负样本刚好被隔开，即预测值大于该阈值的刚好都是正样本，预测值小于该阈值的刚好都是负样本，这个模型就可以认为是一个完美的模型，此时ROC曲线下方的面积就是1。
#### recall precision f1
* recall = TP / (TP + FN)
* precision = TP / (TP + FP)
* f1 = 2 * precision * recall / (precision + recall)


### 训练技巧
#### lora qlora



### optimazer
  * bgd
  * sgd
  * adam
  * adamw


## AI Agent
### MCP (model context protocol)
* 包含
  * tool
  * resource
  * prompt
