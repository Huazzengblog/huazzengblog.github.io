---
title: BERT
date: 2024-04-21 12:00:00 +/-TTTT
categories: [AI,NLP]
tags: [AI,paper-learing,NLP  ]  # TAG names should always be lowercase
---

## BERT
### Abstract
* based on transformer
* deep bidirecional representation(双向)

### Introduction
* thearoy
  * pre-train representation
  * MLM masked language model
  * next sentence predict
  * based on non-labeled data to train may be better


### Pre-train
* use unlabelled data
* WordPiece 
* Masked LM:
  * 15% token be masked
  * 80% masked token be changed to MASK ;15% changed to random token;15% no change



### fine-turn
* based the pre-trained model
* 