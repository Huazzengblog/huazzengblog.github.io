---
title: recommendation system
date: 2025-01-10 20:45:00 +/-TTTT
categories: [internship,Recommendation ]
tags: [internship,Recommendation ]
---
# recommendation system

## 推荐系统基础
![alt text](https://raw.githubusercontent.com/huazZengblog/huazZengblog.github.io/main/_posts/img/recommandation-actions.png)

## 召回
### CF 协同过滤
#### itemCF
* 预估用户对物品的兴趣度： **用户对item i 的喜欢程度** * **item i 与item j的相似程度**
item i 为被计算的item

$\sum _{j} like(user,item_{j}) * sim(item_{j},item_{i}) $


$sim(item_{j},item_{i})$ 通过对item i 感兴趣的用户集合$W_{i}$ 和 对item j感兴趣的用户集合$W_{j}$计算相似度
 
 $sim(i_{1},i_{2}) = \frac{W_{1} \cap W_{2}}{\sqrt{ |W_{1}|*|W_{2}|}}$

* 算法流程
  * 离线计算物品之间的相似度，可以快速找到前k个最相似的item
  * 给出用户的last-n item列表，对每个item获取top-k相似列表，最后返回n*k个item，通过上诉公式计算用户对item的兴趣度，然后进行排序，返回一定数量的item

#### Swing召回通道
类似itemCF的召回方式,避免小圈子情况（同一圈子内可能同时关注两个不相同的内容 但是根据itemcf算法无法判断）影响算法对物品相似度的判断出错
加入新的overlap数据，为用户加权计算相似度
* overlap 计算
  * 用户$u_{1}$喜欢的物品记为$J_{1}$
  * 用户$u_{2}$喜欢的物品记为$J_{2}$
  * 定义二者重合度为 $overlap(u_{1},u_{2}) = |J_{1} \cap J_{2}|$
  * overlap越大 二者权重越低
* 相似度计算
  * 喜欢物品$i_{1}$的用户记为$W_{1}$
  * 喜欢物品$i_{2}$的用户记为$W_{2}$
  * 二者交集记为$V= W_{1} \cap W_{2}$
  * $sim(i_{1},i_{2}) = \sum _{u1  \in V} \sum _{u2 \in V} \frac{1}{alpha + overlap(u_{1},u_{2})}$ 
  * alpha 为一个超参数，需要调整

#### UserCF
寻找相似的用户，然后推荐相似用户喜欢的物品
计算item i的兴趣度
$\sum _{j} sim(user,user_{j}) *  like(user_{j},item_{i}) $
* sim 计算
  * 用户$u_{1}$喜欢的物品记为$J_{1}$
  * 用户$u_{2}$喜欢的物品记为$J_{2}$
  * 定义交集为 $I = |J_{1} \cap J_{2}|$
  * sim 为 $sim(u_{1},u_{2}) = \frac{I}{\sqrt{ |J_{1}|*|J_{2}|}}$
  
* 降低热门物品的权重
  * 避免热门物品影响对相似度的判断
  * sim 为 $sim(u_{1},u_{2}) = \frac{\sum{\frac{1}{log(1+n_{l})}}}{\sqrt{ |J_{1}|*|J_{2}|}}$
  * $n_{l} $ 为物品被喜欢的次数$ 反应热门程度

* 算法流程
  * 建立索引
    * 用户到物品列表
    * 用户到相似用户到列表
  * 计算相似的用户
  * 获取用户感兴趣的物品列表，获取列表
  * 将列表中的物品进行兴趣度计算，重新排序
  
### 向量召回
#### 矩阵补充
* 缺陷
  * 仅用id ebedding 没利用物品 用户属性
  * 负样本的选取方式不对
  * 做训练的方法不够好
* 兴趣分数到计算
  * 通过用户与物品的交互程度来判断分数高低
* 最近邻查找

![alt text](https://raw.githubusercontent.com/huazZengblog/huazZengblog.github.io/main/_posts/img/recommandsys/recommandsys-matrix.png)


### 双塔模型
* 特征
  * id
  * 离散特征
  * 连续特征
* 双塔
  * 针对用户做特征处理
  * 针对物品做特征处理
#### 训练
  * pointwise
    * 将召回当作而分类问题
    * 使得正样本的cos值接近+1 负样本接近=1
    * 正负样本比例控制在1:2 或 1:3
  * pairwise
    * 计算正样本和负样本 与用户的相似度 ，鼓励模型对正样本的推荐
    * Triplet hinge loss :$loss = max(0, margin + pos_score - neg_score)$ 
        margin 为超参数
    * Triple logistic loss :$loss = log(1 + exp(-pos_score + neg_score))$
  * listwise
    * 对比学习
    * loss ： 交叉熵
#### 正负样本
  * 正样本：用户点击的物品
  * 负样本：
    * 曝光但未点击
    * 未被召回
    * 召回但是被粗排和精排排除的
#### 在线训练
全量更新  增量更新

协同训练，单靠一个效果不好，全量更新>增量更新

### 自监督学习

### Deep Retrieveral
**用路径表征物体**
#### 索引
depth = 3
width = 4
路径长度 = depth
* 索引1 ： item -> list<path>
  * 一个物品对应多条路径
* 索引2 ： path -> list<item>
  * 一条路径对应多个物品

#### 预估模型
使用预估模型预估用户对路径的兴趣分数，使用神经网络进行预测
* 假设用三个节点表示一个数据，path = [a,b,c]
* 给定用户特征x，预估用户对a的兴趣分数
* 给定用户特征x，a，预估用户对b的兴趣分数
* 给定用户特征x，a，b，预估用户对c的兴趣分数
* 对路径的兴趣分数 ： 三个兴趣分数相乘
有点像序列生成的过程，三层神经网络，不共享参数，使用上一层的最高的兴趣分数的节点的embed 加上x进行下一层的计算
可以采用bean search 来获取路径，减少搜索空间

#### 线上召回
* 先拿到用户特征
* 进行预估，获得路径
* 通过索引查找路径相关的物品，简单排序，输出子集

#### 离线训练
* 同时学习神经网络参数和物品表征
* 神经网络参数用于预测兴趣分数，物品表征指的是多条路径

* 损失函数为负对数损失
  * 对数内容为：正样本的对应路径的兴趣分数之积，需要提高正样本的每个路径的兴趣分数
-------
* 物品与路径的相关性分数 $score(item,path) = \sum _{user}{p(path|user)*click(user|item)}$
  * $p(path|user) = p([a,b,c] | user)$
  * 通过 $loss(item) = -log(\sum score(item,path))$
  * 为了避免物品都集中到一条路径上，为loss加上正则化
    * reg(path) = (number of item in path) ** 4
  * 使用贪心算法进行路径选择
#### 其他召回渠道
* 地理位置召回
  * GeoHash --> 优质笔记列表
  * GeoHash 表示地图上的一个区域
  * 优质区域列表为区域内的优质笔记
* 同城召回
  * 城市 --> 优质笔记列表
* 作者召回
  * 用户 --> 关注的作者
  * 作者 --> 关注的笔记
  * 流程 ： 用户 --> 作者 --> 笔记 
* 有交互的作者召回
  * 用户 --> 有交互的作者列表
  * 作者列表 --> 笔记
* 相似作者召回
  * 作者 --> 相似作者列表
  * 用户 -->感兴趣的作者列表
  * 流程 ：用户 --> 感兴趣的作者列表 --> 相似作者列表 --> 笔记
* 缓存召回
  * 复用前n次精排的结果
  * 把精排排序靠前但是没有曝光的内容缓存下来，作为一个特殊的召回通道
  * 退场机制
    * 超过曝光 退场
    * FIFO，缓存满了，先进先退场
    * 被召回十次，就退场
    * 缓存三天，推场
### 曝光过滤 & bloom filter
* 曝光过滤
  * 如果用户看过某个物品片，就不要再推荐
  * 对于每一个用户，记录曝光过的物品
  * 通过记录内容，进行召回内容的过滤
* bloom filter
  * 返回no，则物体一定不在记录中
  * 返回yes，则物体可能在记录中
  * bloom filter ：对物品进行hash，向量长度为m bit，有k个哈希函数
  * 向量中已经曝光的物品hash值位置为1
  * 可能存在hash冲突，误伤率为hash冲突率
  * hash函数数量增加时，过滤能力增强，如果存在3个hash函数，只有三个hash函数都返回yes，则一定在记录中；否则就不再在记录中

## 排序
### 多目标模型
* 输入：  
  * 用户特征
  * 物品特征
  * 统计特征 ： 用户近期的点击互动情况，作者的...
  * 场景特征 ： 周末 节日
* 输出
  * 点击率
  * 点赞率
  * 收藏率
  * 转发率

* 训练
  * 预估结果为 $p_{点击}$ ， $p_{点赞}$ ， $p_{收藏}$ ， $p_{转发}$
  * 实际结果为 $y_{点击}$ ， $y_{点赞}$ ， $y_{收藏}$ ， $y_{转发}$
  * 损失函数为： $loss = \sum_{i=1}^{4}alpha_i * CrossEntropy(p_i,y_i)$
  * 困难
    * 负样本过多，可以进行负样本降采样
  * 预估值校准
    * 为什么做校准：因为对负样本进行了降采样，所以预估值会高于现实值
    * 预估值校准：$p_{true} = \frac{a * p_{pred}}{(1-p_{pred}) + a * p_{pred}}$

### Multi-gate  MoE MMoE
![alt text](_posts/img/recommandsys/RS-1.png)
![alt text](_posts/img/recommandsys/RS-1.png)
* 极化现象的出现和解决
  * 某个专家的权重过高，导致其他专家并没有起到作用
  * 使用dropout解决，每次固定mask掉一部分专家
  
### 预估分数的融合
1. 加权和 （包含四个项的加权和）
2. 点击率 * 其他项的加权和
3. 视频平台1
   ![alt text](_posts/img/recommandsys/RS-1.png)
4. 视频平台2 
   ![alt text](_posts/img/recommandsys/RS-1.png)
5. 电商
  ![alt text](_posts/img/recommandsys/RS-1.png)  
### 视频播放建模
* 主要特征
  * 播放时长
    * 将最后一个全连接层的输出记为Z。设p = sigmoid(Z)
    * 实际播放时长为t
    * 使用交叉熵作为loss ： $loss = -（log(p) * t + log(1-p) * (1-t)）$
    * 在线上推理时，以exp（z）作为预估的播放时长
  * 完播率
    * 回归方法，以交叉熵作为loss
    * 分类方法，设置阈值，超过阈值为正样本，其余为负样本
    * 在实践中，不能直接把预估的完播率用到融分公式中
    * $p_{finish} = \frac {p_{完播率}}  {f(time_{视频时长})}$
### 排序模型使用的特征
* 用户画像
  * 用户ID
  * 统计学属性：性别，年龄
  * 账号信息 ： 新老，活跃度
  * 感兴趣的方向
* 物品画像
  * 物品ID
  * 发布实践
  * 城市，GeoHash
  * tag 标签
  * 字数，图片数
  * 内容信息量，图片美学（提前训练的CV NLP模型计算）
* 用户统计特征
  * 用户最近的互动情况
  * 用户对图文和视频笔记的偏好
  * 用户对不同标签的笔记的偏好
* 笔记统计特征：
  * 笔记最近的互动情况
  * 受众的分布：性别 年龄...
  * 作者指标
    * 发布笔记数
    * 粉丝数
    * 消费指标（点赞率等等） 反应之前笔记的水平
* 场景特征
  * 用户定位
  * 当前时刻 早中晚
  * 是否是周末
  * 手机品牌，型号，操作系统
* 特征处理
## 特征交叉

## 行为序列


## 重排


## 