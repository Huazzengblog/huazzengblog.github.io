---
title: recommendation system
date: 2025-01-10 20:45:00 +/-TTTT
categories: [internship,Recommendation ]
tags: [internship,Recommendation ]
---
# recommendation system

## 推荐系统基础
![alt text](https://raw.githubusercontent.com/huazZengblog/huazZengblog.github.io/main/_posts/img/recommandation-actions.png)

## 召回
### CF 协同过滤
#### itemCF
* 预估用户对物品的兴趣度： **用户对item i 的喜欢程度** * **item i 与item j的相似程度**
item i 为被计算的item

$\sum _{j} like(user,item_{j}) * sim(item_{j},item_{i}) $


$sim(item_{j},item_{i})$ 通过对item i 感兴趣的用户集合$W_{i}$ 和 对item j感兴趣的用户集合$W_{j}$计算相似度
 
 $sim(i_{1},i_{2}) = \frac{W_{1} \cap W_{2}}{\sqrt{ |W_{1}|*|W_{2}|}}$

* 算法流程
  * 离线计算物品之间的相似度，可以快速找到前k个最相似的item
  * 给出用户的last-n item列表，对每个item获取top-k相似列表，最后返回n*k个item，通过上诉公式计算用户对item的兴趣度，然后进行排序，返回一定数量的item

#### Swing召回通道
类似itemCF的召回方式,避免小圈子情况（同一圈子内可能同时关注两个不相同的内容 但是根据itemcf算法无法判断）影响算法对物品相似度的判断出错
加入新的overlap数据，为用户加权计算相似度
* overlap 计算
  * 用户$u_{1}$喜欢的物品记为$J_{1}$
  * 用户$u_{2}$喜欢的物品记为$J_{2}$
  * 定义二者重合度为 $overlap(u_{1},u_{2}) = |J_{1} \cap J_{2}|$
  * overlap越大 二者权重越低
* 相似度计算
  * 喜欢物品$i_{1}$的用户记为$W_{1}$
  * 喜欢物品$i_{2}$的用户记为$W_{2}$
  * 二者交集记为$V= W_{1} \cap W_{2}$
  * $sim(i_{1},i_{2}) = \sum _{u1  \in V} \sum _{u2 \in V} \frac{1}{alpha + overlap(u_{1},u_{2})}$ 
  * alpha 为一个超参数，需要调整

#### UserCF
寻找相似的用户，然后推荐相似用户喜欢的物品
计算item i的兴趣度
$\sum _{j} sim(user,user_{j}) *  like(user_{j},item_{i}) $
* sim 计算
  * 用户$u_{1}$喜欢的物品记为$J_{1}$
  * 用户$u_{2}$喜欢的物品记为$J_{2}$
  * 定义交集为 $I = |J_{1} \cap J_{2}|$
  * sim 为 $sim(u_{1},u_{2}) = \frac{I}{\sqrt{ |J_{1}|*|J_{2}|}}$
  
* 降低热门物品的权重
  * 避免热门物品影响对相似度的判断
  * sim 为 $sim(u_{1},u_{2}) = \frac{\sum{\frac{1}{log(1+n_{l})}}}{\sqrt{ |J_{1}|*|J_{2}|}}$
  * $n_{l} $ 为物品被喜欢的次数$ 反应热门程度

* 算法流程
  * 建立索引
    * 用户到物品列表
    * 用户到相似用户到列表
  * 计算相似的用户
  * 获取用户感兴趣的物品列表，获取列表
  * 将列表中的物品进行兴趣度计算，重新排序
  
### 向量召回
#### 矩阵补充
* 缺陷
  * 仅用id ebedding 没利用物品 用户属性
  * 负样本的选取方式不对
  * 做训练的方法不够好
* 兴趣分数到计算
  * 通过用户与物品的交互程度来判断分数高低
* 最近邻查找

![alt text](https://raw.githubusercontent.com/huazZengblog/huazZengblog.github.io/main/_posts/img/recommandsys/recommandsys-matrix.png)


### 双塔模型
* 特征
  * id
  * 离散特征
  * 连续特征
* 双塔
  * 针对用户做特征处理
  * 针对物品做特征处理
#### 训练
  * pointwise
    * 将召回当作而分类问题
    * 使得正样本的cos值接近+1 负样本接近=1
    * 正负样本比例控制在1:2 或 1:3
  * pairwise
    * 计算正样本和负样本 与用户的相似度 ，鼓励模型对正样本的推荐
    * Triplet hinge loss :$loss = max(0, margin + pos_score - neg_score)$ 
        margin 为超参数
    * Triple logistic loss :$loss = log(1 + exp(-pos_score + neg_score))$
  * listwise
    * 对比学习
    * loss ： 交叉熵
#### 正负样本
  * 正样本：用户点击的物品
  * 负样本：
    * 曝光但未点击
    * 未被召回
    * 召回但是被粗排和精排排除的
#### 在线训练
全量更新  增量更新

协同训练，单靠一个效果不好，全量更新>增量更新

### 自监督学习

### Deep Retrieveral
**用路径表征物体**
#### 索引
depth = 3
width = 4
路径长度 = depth
* 索引1 ： item -> list<path>
  * 一个物品对应多条路径
* 索引2 ： path -> list<item>
  * 一条路径对应多个物品

#### 预估模型
使用预估模型预估用户对路径的兴趣分数，使用神经网络进行预测
* 假设用三个节点表示一个数据，path = [a,b,c]
* 给定用户特征x，预估用户对a的兴趣分数
* 给定用户特征x，a，预估用户对b的兴趣分数
* 给定用户特征x，a，b，预估用户对c的兴趣分数
* 对路径的兴趣分数 ： 三个兴趣分数相乘
有点像序列生成的过程，三层神经网络，不共享参数，使用上一层的最高的兴趣分数的节点的embed 加上x进行下一层的计算
可以采用bean search 来获取路径，减少搜索空间

#### 线上召回
* 先拿到用户特征
* 进行预估，获得路径
* 通过索引查找路径相关的物品，简单排序，输出子集

#### 离线训练
* 同时学习神经网络参数和物品表征
* 神经网络参数用于预测兴趣分数，物品表征指的是多条路径

* 损失函数为负对数损失
  * 对数内容为：正样本的对应路径的兴趣分数之积，需要提高正样本的每个路径的兴趣分数
-------
* 物品与路径的相关性分数 $score(item,path) = \sum _{user}{p(path|user)*click(user|item)}$
  * $p(path|user) = p([a,b,c] | user)$
  * 通过 $loss(item) = -log(\sum score(item,path))$
  * 为了避免物品都集中到一条路径上，为loss加上正则化
    * reg(path) = (number of item in path) ** 4
  * 使用贪心算法进行路径选择
#### 其他召回渠道


#### 曝光过滤

## 排序
### 多目标模型

## 特征交叉

## 行为序列


## 重排


## 