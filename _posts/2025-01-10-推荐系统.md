---
title: recommendation system
date: 2025-01-10 20:45:00 +/-TTTT
categories: [internship,Recommendation ]
tags: [internship,Recommendation ]
---
# recommendation system

## 推荐系统基础
![alt text](https://raw.githubusercontent.com/huazZengblog/huazZengblog.github.io/main/_posts/img/recommandation-actions.png)

## 召回
### CF 协同过滤
#### itemCF
* 预估用户对物品的兴趣度： **用户对item i 的喜欢程度** * **item i 与item j的相似程度**
item i 为被计算的item

$\sum _{j} like(user,item_{j}) * sim(item_{j},item_{i}) $


$sim(item_{j},item_{i})$ 通过对item i 感兴趣的用户集合$W_{i}$ 和 对item j感兴趣的用户集合$W_{j}$计算相似度
 
 $sim(i_{1},i_{2}) = \frac{W_{1} \cap W_{2}}{\sqrt{ |W_{1}|*|W_{2}|}}$

* 算法流程
  * 离线计算物品之间的相似度，可以快速找到前k个最相似的item
  * 给出用户的last-n item列表，对每个item获取top-k相似列表，最后返回n*k个item，通过上诉公式计算用户对item的兴趣度，然后进行排序，返回一定数量的item

#### Swing召回通道
类似itemCF的召回方式,避免小圈子情况（同一圈子内可能同时关注两个不相同的内容 但是根据itemcf算法无法判断）影响算法对物品相似度的判断出错
加入新的overlap数据，为用户加权计算相似度
* overlap 计算
  * 用户$u_{1}$喜欢的物品记为$J_{1}$
  * 用户$u_{2}$喜欢的物品记为$J_{2}$
  * 定义二者重合度为 $overlap(u_{1},u_{2}) = |J_{1} \cap J_{2}|$
  * overlap越大 二者权重越低
* 相似度计算
  * 喜欢物品$i_{1}$的用户记为$W_{1}$
  * 喜欢物品$i_{2}$的用户记为$W_{2}$
  * 二者交集记为$V= W_{1} \cap W_{2}$
  * $sim(i_{1},i_{2}) = \sum _{u1  \in V} \sum _{u2 \in V} \frac{1}{alpha + overlap(u_{1},u_{2})}$ 
  * alpha 为一个超参数，需要调整

#### UserCF
寻找相似的用户，然后推荐相似用户喜欢的物品
计算item i的兴趣度
$\sum _{j} sim(user,user_{j}) *  like(user_{j},item_{i}) $
* sim 计算
  * 用户$u_{1}$喜欢的物品记为$J_{1}$
  * 用户$u_{2}$喜欢的物品记为$J_{2}$
  * 定义交集为 $I = |J_{1} \cap J_{2}|$
  * sim 为 $sim(u_{1},u_{2}) = \frac{I}{\sqrt{ |J_{1}|*|J_{2}|}}$
  
* 降低热门物品的权重
  * 避免热门物品影响对相似度的判断
  * sim 为 $sim(u_{1},u_{2}) = \frac{\sum{\frac{1}{log(1+n_{l})}}}{\sqrt{ |J_{1}|*|J_{2}|}}$
  * $n_{l} $ 为物品被喜欢的次数$ 反应热门程度

* 算法流程
  * 建立索引
    * 用户到物品列表
    * 用户到相似用户到列表
  * 计算相似的用户
  * 获取用户感兴趣的物品列表，获取列表
  * 将列表中的物品进行兴趣度计算，重新排序
  
### 向量召回
#### 矩阵补充
* 缺陷
  * 仅用id ebedding 没利用物品 用户属性
  * 负样本的选取方式不对
  * 做训练的方法不够好
* 兴趣分数到计算
  * 通过用户与物品的交互程度来判断分数高低
* 最近邻查找

![alt text](https://raw.githubusercontent.com/huazZengblog/huazZengblog.github.io/main/_posts/img/recommandsys/recommandsys-matrix.png)


### 双塔模型
* 特征
  * id
  * 离散特征
  * 连续特征
* 双塔
  * 针对用户做特征处理
  * 针对物品做特征处理
#### 训练
  * pointwise
    * 将召回当作而分类问题
    * 使得正样本的cos值接近+1 负样本接近=1
    * 正负样本比例控制在1:2 或 1:3
  * pairwise
    * 计算正样本和负样本 与用户的相似度 ，鼓励模型对正样本的推荐
    * Triplet hinge loss :$loss = max(0, margin + pos_score - neg_score)$ 
        margin 为超参数
    * Triple logistic loss :$loss = log(1 + exp(-pos_score + neg_score))$
  * listwise
    * 对比学习
    * loss ： 交叉熵
#### 正负样本
  * 正样本：用户点击的物品
  * 负样本：
    * 曝光但未点击
    * 未被召回
    * 召回但是被粗排和精排排除的
#### 在线训练
全量更新  增量更新

协同训练，单靠一个效果不好，全量更新>增量更新

### 自监督学习

### Deep Retrieveral
**用路径表征物体**
#### 索引
depth = 3
width = 4
路径长度 = depth
* 索引1 ： item -> list<path>
  * 一个物品对应多条路径
* 索引2 ： path -> list<item>
  * 一条路径对应多个物品

#### 预估模型
使用预估模型预估用户对路径的兴趣分数，使用神经网络进行预测
* 假设用三个节点表示一个数据，path = [a,b,c]
* 给定用户特征x，预估用户对a的兴趣分数
* 给定用户特征x，a，预估用户对b的兴趣分数
* 给定用户特征x，a，b，预估用户对c的兴趣分数
* 对路径的兴趣分数 ： 三个兴趣分数相乘
有点像序列生成的过程，三层神经网络，不共享参数，使用上一层的最高的兴趣分数的节点的embed 加上x进行下一层的计算
可以采用bean search 来获取路径，减少搜索空间

#### 线上召回
* 先拿到用户特征
* 进行预估，获得路径
* 通过索引查找路径相关的物品，简单排序，输出子集

#### 离线训练
* 同时学习神经网络参数和物品表征
* 神经网络参数用于预测兴趣分数，物品表征指的是多条路径

* 损失函数为负对数损失
  * 对数内容为：正样本的对应路径的兴趣分数之积，需要提高正样本的每个路径的兴趣分数

* 物品与路径的相关性分数 $score(item,path) = \sum _{user}{p(path|user)*click(user|item)}$
  * $p(path|user) = p([a,b,c] | user)$
  * 通过 $loss(item) = -log(\sum score(item,path))$
  * 为了避免物品都集中到一条路径上，为loss加上正则化
    * reg(path) = (number of item in path) ** 4
  * 使用贪心算法进行路径选择
#### 其他召回渠道
* 地理位置召回
  * GeoHash --> 优质笔记列表
  * GeoHash 表示地图上的一个区域
  * 优质区域列表为区域内的优质笔记
* 同城召回
  * 城市 --> 优质笔记列表
* 作者召回
  * 用户 --> 关注的作者
  * 作者 --> 关注的笔记
  * 流程 ： 用户 --> 作者 --> 笔记 
* 有交互的作者召回
  * 用户 --> 有交互的作者列表
  * 作者列表 --> 笔记
* 相似作者召回
  * 作者 --> 相似作者列表
  * 用户 -->感兴趣的作者列表
  * 流程 ：用户 --> 感兴趣的作者列表 --> 相似作者列表 --> 笔记
* 缓存召回
  * 复用前n次精排的结果
  * 把精排排序靠前但是没有曝光的内容缓存下来，作为一个特殊的召回通道
  * 退场机制
    * 超过曝光 退场
    * FIFO，缓存满了，先进先退场
    * 被召回十次，就退场
    * 缓存三天，推场
### 曝光过滤 & bloom filter
* 曝光过滤
  * 如果用户看过某个物品片，就不要再推荐
  * 对于每一个用户，记录曝光过的物品
  * 通过记录内容，进行召回内容的过滤
* bloom filter
  * 返回no，则物体一定不在记录中
  * 返回yes，则物体可能在记录中
  * bloom filter ：对物品进行hash，向量长度为m bit，有k个哈希函数
  * 向量中已经曝光的物品hash值位置为1
  * 可能存在hash冲突，误伤率为hash冲突率
  * hash函数数量增加时，过滤能力增强，如果存在3个hash函数，只有三个hash函数都返回yes，则一定在记录中；否则就不再在记录中

## 排序
### 多目标模型
* 输入：  
  * 用户特征
  * 物品特征
  * 统计特征 ： 用户近期的点击互动情况，作者的...
  * 场景特征 ： 周末 节日
* 输出
  * 点击率
  * 点赞率
  * 收藏率
  * 转发率

* 训练
  * 预估结果为 $p_{点击}$ ， $p_{点赞}$ ， $p_{收藏}$ ， $p_{转发}$
  * 实际结果为 $y_{点击}$ ， $y_{点赞}$ ， $y_{收藏}$ ， $y_{转发}$
  * 损失函数为： $loss = \sum_{i=1}^{4}alpha_i * CrossEntropy(p_i,y_i)$
  * 困难
    * 负样本过多，可以进行负样本降采样
  * 预估值校准
    * 为什么做校准：因为对负样本进行了降采样，所以预估值会高于现实值
    * 预估值校准：$p_{true} = \frac{a * p_{pred}}{(1-p_{pred}) + a * p_{pred}}$

### Multi-gate  MoE MMoE
![alt text](https://raw.githubusercontent.com/huazZengblog/huazZengblog.github.io/main/_posts/img/recommandsys/RS-1.png)
![alt text](https://raw.githubusercontent.com/huazZengblog/huazZengblog.github.io/main/_posts/img/recommandsys/RS-1.png)
* 极化现象的出现和解决
  * 某个专家的权重过高，导致其他专家并没有起到作用
  * 使用dropout解决，每次固定mask掉一部分专家
  
### 预估分数的融合
1. 加权和 （包含四个项的加权和）
2. 点击率 * 其他项的加权和
3. 视频平台1
   ![alt text](https://raw.githubusercontent.com/huazZengblog/huazZengblog.github.io/main/_posts/img/recommandsys/RS-1.png)
4. 视频平台2 
   ![alt text](https://raw.githubusercontent.com/huazZengblog/huazZengblog.github.io/main/_posts/img/recommandsys/RS-1.png)
5. 电商
  ![alt text](https://raw.githubusercontent.com/huazZengblog/huazZengblog.github.io/main/_posts/img/recommandsys/RS-1.png)  
### 视频播放建模
* 主要特征
  * 播放时长
    * 将最后一个全连接层的输出记为Z。设p = sigmoid(Z)
    * 实际播放时长为t
    * 使用交叉熵作为loss ： $loss = -（log(p) * t + log(1-p) * (1-t)）$
    * 在线上推理时，以exp（z）作为预估的播放时长
  * 完播率
    * 回归方法，以交叉熵作为loss
    * 分类方法，设置阈值，超过阈值为正样本，其余为负样本
    * 在实践中，不能直接把预估的完播率用到融分公式中
    * $p_{finish} = \frac {p_{完播率}}  {f(time_{视频时长})}$
### 排序模型使用的特征
* 用户画像
  * 用户ID
  * 统计学属性：性别，年龄
  * 账号信息 ： 新老，活跃度
  * 感兴趣的方向
* 物品画像
  * 物品ID
  * 发布实践
  * 城市，GeoHash
  * tag 标签
  * 字数，图片数
  * 内容信息量，图片美学（提前训练的CV NLP模型计算）
* 用户统计特征
  * 用户最近的互动情况
  * 用户对图文和视频笔记的偏好
  * 用户对不同标签的笔记的偏好
* 笔记统计特征：
  * 笔记最近的互动情况
  * 受众的分布：性别 年龄...
  * 作者指标
    * 发布笔记数
    * 粉丝数
    * 消费指标（点赞率等等） 反应之前笔记的水平
* 场景特征
  * 用户定位
  * 当前时刻 早中晚
  * 是否是周末
  * 手机品牌，型号，操作系统
* 特征处理

### 精排  VS 粗排
* 特征交融的时间
  * 前期交融：如果有n篇笔记则需要n次推理
  * 后期交融：双塔模型，预先计算好笔记的表征，线上只需要算用户表征即可
* 粗排
  * 三塔模型
  ![alt text](https://raw.githubusercontent.com/huazZengblog/huazZengblog.github.io/main/_posts/img/recommandsys/RS-3Towers.png)
    * 用户特征只计算一次
    * 笔记特征可以缓存
    * 交叉特征需要重新计算


## 特征交叉
### FM


## 行为序列


## 重排


## model

### 经典模型
* itemcf
  * swing
* usercf 
* 双塔模型
  
### 特征交叉
#### GBDT

* 一、基本概念
GBDT 属于集成学习中 Boosting 类的算法，通过构建和组合多个决策树来提升预测的准确性。其核心在于迭代地训练多个决策树（基学习器），每个新的决策树都旨在纠正前一棵树的预测误差，最终将所有树的结果累加起来得到最终的预测结果。
* 二、组成部分
在 GBDT 中使用的是回归树，因为 GBDT 的核心是累加所有树的结果作为最终结果，分类树的结果无法进行累加。
梯度提升：基于梯度下降的思想，通过迭代的方式逐步优化模型。每一次迭代都基于上一轮模型的预测误差（负梯度，当损失函数是平方损失函数时，负梯度就是残差 ）来训练新的决策树，使得模型的预测值不断接近真实值，损失函数不断减小。
* 三、工作流程
初始化模型：通常从一个简单的模型开始，比如常数值模型。以预测客户年龄为例，可能先假设一个初始的预测值，如 30 岁。
构建决策树：
计算当前模型的负梯度（在平方损失函数下就是残差），例如客户真实年龄是 40 岁，初始模型预测为 30 岁，那么残差就是 10 岁。这个残差表示当前模型需要被修正的部分。
基于负梯度（残差）训练一棵新的决策树，让这棵树尝试拟合残差。比如新树预测可以修正 5 岁的偏差。
更新模型：将新树的预测结果与之前的模型结果相加，得到更新后的模型。如前面例子中，更新后的预测结果变为 30 + 5 = 35 岁。
迭代过程：重复上述计算负梯度、构建新树、更新模型的过程，不断减少误差。例如后续可能又通过新的树分别修正 3 岁、1 岁的偏差，直到达到预设的停止条件（如残差值小于给定阈值、树的数量达到上限等） 。
* 四、目标函数与优化
目标函数：目标是通过多个决策树模型来最小化预测误差，即通过不断调整模型参数，使得损失函数的值最小。常见的损失函数有均方误差（MSE，用于回归问题）、对数损失函数（用于分类问题）等。
优化方法：利用损失函数的负梯度在当前模型的值作为回归问题提升树算法中的残差的近似值去拟合一个回归树，通过不断迭代，沿着梯度方向调整模型参数，使损失函数尽可能快地减小，尽快收敛到局部最优解或全局最优解。
* 变体 ：

| 对比项                  | XGBoost                                                                                | LightGBM                                                                                                              | CatBoost                                                                                                       |
| ----------------------- | -------------------------------------------------------------------------------------- | --------------------------------------------------------------------------------------------------------------------- | -------------------------------------------------------------------------------------------------------------- |
| **基学习器构建方式**    | 按层（level-wise）生长，对所有叶子节点同时进行分裂，每层分裂后叶子节点数翻倍           | 按叶子（leaf-wise）生长，每次选择增益最大的叶子节点进行分裂，可能生成更深的树                                         | 按层（level-wise）生长，类似 XGBoost，但在处理类别特征等方面有独特方式                                         |
| **特征处理 - 连续特征** | 预排序算法，对每个特征的所有取值排序，遍历寻找最优分裂点，计算量大                     | 直方图算法，将连续特征离散化为直方图（默认 256 个 bins），基于直方图计算分裂增益，计算量小                            | 与 LightGBM 类似的直方图算法，但在处理过程中会考虑目标统计信息                                                 |
| **特征处理 - 类别特征** | 需手动进行编码转换（如独热编码等），否则无法直接处理                                   | 可直接处理类别特征，通过对类别特征进行重编码来处理                                                                    | 可直接处理类别特征，采用目标统计编码方式，自动学习类别特征与目标变量的关系                                     |
| **防止过拟合方式**      | 目标函数中加入 L1 和 L2 正则化项；设置树的深度、叶子节点数量等参数                     | 采用直方图算法减少过拟合风险；可设置树的最大深度等参数；梯度单边采样（GOSS）和互斥特征捆绑（EFB）技术进一步防止过拟合 | 有序提升（Ordered Boosting）减少过拟合；内置多种正则化方法；在处理类别特征时通过目标统计编码也有助于防止过拟合 |
| **并行计算**            | 支持列（特征）方向的并行计算，不同线程可同时处理不同特征                               | 支持特征并行（不同机器处理不同特征，合并最优分裂点）和数据并行（基于直方图的分散 - 聚合方式），通信开销小             | 支持多线程并行计算，在处理大规模数据时也有一定的并行能力，但在并行策略上与 LightGBM 有所不同                   |
| **内存占用**            | 由于预排序算法，内存占用相对较高，尤其是在处理大规模数据集和高维特征时                 | 基于直方图算法，内存占用较低，相比 XGBoost 有明显优势                                                                 | 内存占用介于 XGBoost 和 LightGBM 之间，对内存的管理也较为高效                                                  |
| **训练速度**            | 相对较快，尤其是在大规模数据集上利用并行计算加速训练，但相比 LightGBM 训练速度可能较慢 | 训练速度快，在处理大规模数据时优势明显，得益于直方图算法、GOSS 和 EFB 等技术                                          | 训练速度在小数据集上表现出色，在大数据集上也有较好的性能，整体训练速度相对较快                                 |
| **预测精度**            | 通常具有较高的预测精度，在许多实际应用中表现良好                                       | 在一些情况下预测精度与 XGBoost 相当，有时甚至更高，尤其是在处理大规模数据和复杂特征时                                 | 预测精度较高，在处理类别特征和小数据集时优势明显，对一些复杂问题也能取得较好的效果                             |
| **调参难度**            | 需要对参数有一定了解，调参相对复杂，如学习率、树的深度、正则化参数等都需要仔细调整     | 调参相对简单一些，一些默认参数能在很多场景下取得不错的效果，但为了进一步优化性能仍需要一定的调参技巧                  | 调参相对简单，具有一定的“自动化”能力，默认参数能在很多情况下给出较好的结果，对新手相对友好                     |
| **适用场景**            | 广泛应用于各种数据挖掘和机器学习任务，尤其在结构化数据的回归和分类问题中表现出色       | 适用于大规模数据集和高维数据的处理，在竞赛和工业界的大规模推荐系统、预测任务等场景中应用广泛                          | 适用于包含大量类别特征的数据，小数据集上表现优秀，也适用于对预测精度要求较高且对调参不太熟悉的用户             |





#### FM

#### FFM

#### DeepFM

#### wide & deep

#### DCN 


#### DSSM


#### YoutubeDNN

#### AFM

### 序列建模
#### DIN

#### DIEN

#### DSIN

#### SIM

#### MIMN


### 多目标模型
#### shared-nothing & shared - bottom


#### MMoE


#### PLE

#### STAR

#### PPNet

#### ESSM

#### STEM
