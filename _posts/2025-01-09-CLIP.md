---
title: CLIP
date: 2025-01-09 00:455:00 +/-TTTT
categories: AI,multi-modal
tags: [AI,multi-modal]
---
# CLIP

Learning Transferable Visual Models From Natural Language Supervision
论文地址：[Learning Transferable Visual Models From Natural Language Supervision](https://arxiv.org/pdf/2103.00020)
## 模型结构
![alt text](https://raw.githubusercontent.com/huazZengblog/huazZengblog.github.io/main/_posts/img/clip-pretrain.png)
![alt text](https://raw.githubusercontent.com/huazZengblog/huazZengblog.github.io/main/_posts/img/clip-infer.png)
* 在预训练时，clip采用两个编码器，分别编码文本和图像，形成n*n的相似度矩阵，对角线为正样本，其余为负样本
* 在推理时，clip采用一个编码器，编码图像，对文本进行prompt，把相关的label嵌入，嵌入后与图像的编码进行对比，计算相似度，取相似度最大的label为预测结果
  * 在这种情况下，clip具有了泛化到任意标签上


## abstract
* 提出的意图：对于传统的图像识别，限定好了标签类，泛化能力有限，得到新的标签，则需要对应标签的数据来训练，CLIP则**Learning directly from raw text about images is a promising  alternative which leverages a much broader source of supervision.**

* 采用的方式：多模态的对比学习
* 训练结束后，可以直接在下游任务进行zero-shot learning


## introduce
* 从nlp领域的预训练方法中，使用预训练已经在nlp领域获得成功，希望迁移到图像识别领域
* 相较之前的类似的弱监督的学习方法，clip使用更大的数据集，训练更大的模型（几十万 vs 4 亿）
  * 之前的方法不是不行 只是规模不够大
* 数据集 400m对text-img pairs
* 对比cv领域的有监督训练方法，clip的泛化能力更强，特别是对于抽象以及对抗性样本
  
## approach
* nlp ： deep contextual representation learning
* 模型
  * 编码器： 
    * img ： resnet
    * text ： transformer
  * 两个输入经过编码器后 还需要经过一次投射层
    * 原因
      * 对齐空间
      * 过一层mlp 对比学习效果会好；在moco等对比学习论文中，采用非线性投射层 提点效果好，但是clip发现在多模态训练时线性与非线性的效果差别不打
* 数据
* 训练方法：
  * 选择一个高校的训练方法
    * 如果采用预测型算法，类似gpt的方法，一个图片可能有多个描述，预测结果很难去监督
    * 所以采用了对比学习的方法，只预测当前图片和文本是否配对
  * 混合精度训练

## experiment
* 为什么使用prompt engineering 来将label转化为一个句子
  * 单词具有多义性，可能一个单词会有歧义
  * 预训练时使用的就是句子，如果在推理时，直接使用label，会出现distribution gap
  * 采用prompt engineering 就会提升一个点
  * 可以根据数据集来强化prompt，使得歧义更少
* prompt ensembling
  * 使用多个prompt 来进行多次预测 最后投票
  
* 数据集overlapping 的实验


## Limitations
* clip 对比对象是 resnet 50，并不是sota，和现在的模型还有差距
  * scaling 还有提升空间
* 在部分数据集的效果也不好
* 泛化能力虽然很好，推理时数据如果没有在训练数据上见过，结果就会差
* 仍然需要从给定的类别里去选取，如果能够生成图像题目，则与gpt方法更加相似
* 数据局限性
  * 1. 数据利用不高效，可以采用对比学习中其他的高效数据使用方法
    * 数据增强
    * 自监督
    * 伪标签
  * 2. 测试训练集的类似泄露
  * 3. 训练集的内容存在偏见
  * 4. 给clip提供训练样本时 效果变差