---
title: MoCo
date: 2024-04-21 12:00:00 +/-TTTT
categories: [AI,CV]
tags: [AI,paper-learing,CV,pre-train  ]  # TAG names should always be lowercase
---

## MoCo
**Momentum Contrast**
### Abstract
* dictionary look-up
* linear protocol 冻住预训练好的主干，只微调全连接层
  

### Introducttion
* difference between CV NLP
* encoders to perform a dictionary look-up;key is similar to matching key(positive)
* require in building dictionary
  * 字典越大越好
  * 一致性 key应该由相同和相似的编码器得到
* Model
  * 采用queue 降低训练时的内存开销
  * 使用动量编码器 增大动量值 **使得参数改变缓慢，保持一致性**

### Relative   Work
* 之前对比学习的受限
  * end to end ：限制了dictionary size，只能与minibatch大小一致
  * memory bank 
    * 预先存储了图像的特征，每次抽样出样本做batch
    * 更新encoder后，batch中的样本通过新的encoder后 重新存入memory bank
    * 牺牲了特征一致性，构造较大的字典

* pretex tasks代理任务
    

* loss fuction
  *   生成式网络 采用prediction 与 fixed target 的区别
  *   判别方法 cross entropy
  *   对比学习 
  *   GAN KL散度 拟合分布

### Method
* Loss Fuction : InfoNCE 
  * noise contrastive **estimation**估计 近似 
* 编码器在不断改变
* queue
  * 将字典由队列的方法表示出来 每次移除最老的minibatch
  * reuse 曾经编码好的batch
  * 队列是字典的子集
  * F key 的参数更新 缓慢更新
    * 动量更新参数 由动量m决定
    * 保证key的一致性
* code
  * 初始化 两个编码器一样
  * 获取key 和 query图像，形成正样本对
  * 前向

### experience
* learning rate 
* 微调学习率
* 可迁移的特征
  * 特征归一化 后使用有监督训练的超参来微调